{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook setup\n",
        "**1.** Import the Earth Engine, geemap, and 3rd party libraries."
      ],
      "metadata": {
        "id": "l3__brJmUFvW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHz_8SsJT6Se"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install -q --upgrade altair\n",
        "%pip install h3==3.7.6 tobler\n",
        "import altair as alt\n",
        "\n",
        "import ee\n",
        "import geemap as geemap\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid, make_axes_locatable\n",
        "\n",
        "from shapely.wkt import loads\n",
        "from tobler.util import h3fy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Authenticate and initialize to the Earth Engine service.\n",
        "*  This Requires a Google Cloud Project you have access to that is registered to use Earth Engine\n",
        "\n"
      ],
      "metadata": {
        "id": "fATYuPJiUfGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'sdsc24-nyc' # Change to a project where you have EEE access.\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=project_id) # Change to a project where you have EEE access."
      ],
      "metadata": {
        "id": "uuTzxryfUejt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1 - The Basics\n"
      ],
      "metadata": {
        "id": "ufB8x_SOU7yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add raster data to a map\n",
        "**1.** Load climate data for a given period and display its metadata."
      ],
      "metadata": {
        "id": "IVpHtwkTVJHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sept_2024_climate = (\n",
        "    ee.ImageCollection('ECMWF/ERA5_LAND/MONTHLY_AGGR')\n",
        "    .filterDate('2024-09', '2024-10')\n",
        "    .first()\n",
        ")\n",
        "sept_2024_climate"
      ],
      "metadata": {
        "id": "rzOgKXYwVMAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Instantiate a map object and add the temperature band as a layer with\n",
        "specific visualization properties. Display the map."
      ],
      "metadata": {
        "id": "-UWNbqp8ZBHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = geemap.Map(center=[30, 0], zoom=2)\n",
        "\n",
        "vis_params = {\n",
        "    'bands': ['temperature_2m'],\n",
        "    'min': 229,\n",
        "    'max': 304,\n",
        "    'palette': 'inferno',\n",
        "}\n",
        "m.add_layer(sept_2024_climate, vis_params, 'Temperature (K)')\n",
        "m"
      ],
      "metadata": {
        "id": "iCZOGrUhZFbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add vector data to a map\n",
        "\n",
        "**1.** Create a vector data object with points for three cities."
      ],
      "metadata": {
        "id": "W1QyT6QoZedO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = ee.FeatureCollection([\n",
        "    ee.Feature(ee.Geometry.Point(10.75, 59.91), {'city': 'Oslo'}),\n",
        "    ee.Feature(ee.Geometry.Point(-118.24, 34.05), {'city': 'Los Angeles'}),\n",
        "    ee.Feature(ee.Geometry.Point(103.83, 1.33), {'city': 'Singapore'}),\n",
        "])\n",
        "cities"
      ],
      "metadata": {
        "id": "PwW16XIgZhD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Add the city locations to the map and redisplay it."
      ],
      "metadata": {
        "id": "-x5O3xhVZo5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.add_layer(cities, name='Cities')\n",
        "m"
      ],
      "metadata": {
        "id": "Ny9DtiC8ZqFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Extract the climate data for the three cities as a pandas DataFrame."
      ],
      "metadata": {
        "id": "Aa9YkjCiZ5CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_climates = sept_2024_climate.reduceRegions(cities, ee.Reducer.first())\n",
        "\n",
        "city_climates_dataframe = ee.data.computeFeatures(\n",
        "    {'expression': city_climates, 'fileFormat': 'PANDAS_DATAFRAME'}\n",
        ")\n",
        "city_climates_dataframe"
      ],
      "metadata": {
        "id": "-FFaGkyWZ7qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** Plot the temperature for the cities as a bar chart."
      ],
      "metadata": {
        "id": "pxyhlJEsaJg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(city_climates_dataframe).mark_bar(size=100).encode(\n",
        "    alt.X('city:N', sort='y', axis=alt.Axis(labelAngle=0), title='City'),\n",
        "    alt.Y('temperature_2m:Q', title='Temperature (K)'),\n",
        "    tooltip=[\n",
        "        alt.Tooltip('city:N', title='City'),\n",
        "        alt.Tooltip('temperature_2m:Q', title='Temperature (K)'),\n",
        "    ],\n",
        ").properties(title='September 2024 temperature for selected cities', width=500)"
      ],
      "metadata": {
        "id": "waIfWhAoaGfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Advanced Raster Processing\n"
      ],
      "metadata": {
        "id": "RZTDn4wfagKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** Create a sophisticated cloud-free Sentinel 2 Mosaic\n",
        "This will *dynamically* create a cloud-free mosaic for an entire year's worth of 10m Sentinel 2 Imagery and display it on a geemap.\n",
        "\n",
        "1 year of Sentinel 2 Imagery is ~3.5 petabytes"
      ],
      "metadata": {
        "id": "8zfCGI9HamKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Harmonized Sentinel-2 Level 2A collection.\n",
        "# https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED\n",
        "\n",
        "s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');\n",
        "\n",
        "# Cloud Score+ image collection.\n",
        "# https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED\n",
        "# Note Cloud Score+ is produced from Sentinel-2 Level 1C data\n",
        "# and can be applied to either L1C or L2A collections.\n",
        "\n",
        "csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED');\n",
        "\n",
        "# This function adds a band representing the image timestamp.\n",
        "def maskThreshold(img):\n",
        "  return img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD));\n",
        "\n",
        "# Link both collections for all images with > 60% CS score (60% of what you'd expect to see on a clear day)\n",
        "# Reduce the linked collection by the median of all values at each pixel across each band\n",
        "QA_BAND = 'cs'\n",
        "CLEAR_THRESHOLD = 0.60\n",
        "composite = s2.filterDate('2023-01-01', '2023-12-31').linkCollection(csPlus, [QA_BAND]).map(maskThreshold).median();\n",
        "\n",
        "# Select the R,G, and B bands for visualization and generate an X/Y/Z URL file pattern of the resulting image.\n",
        "composite = composite.select(['B4', 'B3', 'B2'])\n",
        "s2Viz = {'min': 0, 'max': 2500};\n",
        "mapID = composite.getMapId(s2Viz)\n"
      ],
      "metadata": {
        "id": "qzMEXIOla75I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note, if you want to use these tiles elswwhere, you can get the tile pattern\n",
        "xyzURL = mapID['tile_fetcher'].url_format\n",
        "xyzURL"
      ],
      "metadata": {
        "id": "Jyn_Q18Mvhg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Now display the cloud-free mosaic on a geemap\n"
      ],
      "metadata": {
        "id": "KJA1_va3bPWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = geemap.Map(center=[40.791530811684396, -73.95543742118639], zoom=11)\n",
        "\n",
        "m.add_layer(composite, s2Viz, 'S2 CS+ 2022')\n",
        "m"
      ],
      "metadata": {
        "id": "VznDEeElrEYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2 - Dataframes and Time Series\n"
      ],
      "metadata": {
        "id": "WF7zKsytjvf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the last module we worked through some basic operations and visualized the results as map layers. For understanding temporal dynamics, which is a common desire when working with remote sensing, you will want a line graph that shows quantities of a variable over time, commonly known as a time series graph.\n",
        "\n",
        "The [VIIRS](https://developers.google.com/earth-engine/datasets/catalog/NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG) dataset has many uses, including observing \"Nighttime Lights\" which are a proxy for human activity and urban extent.\n",
        "\n",
        "**Our tasks in this exercise:**\n",
        "1. Extracting VIIRS time series data and converting to a pandas dataframe\n",
        "2. Create a 2014-2024 time series graph from VIIRS-DNB data for a point in Seoul, South Korea\n",
        "\n",
        "First, create a split geemap showing the differences between 2014 and 2024"
      ],
      "metadata": {
        "id": "Yp1aE_A5j0Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "viirs2014 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate('2014-01-01','2014-12-31')\n",
        "viirs2024 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate('2024-01-01','2024-12-31')\n",
        "\n",
        "left_layer = geemap.ee_tile_layer(viirs2014.select('avg_rad').median(), {'min':0,'max':10},\"VIIRS 2014\")\n",
        "right_layer = geemap.ee_tile_layer(viirs2024.select('avg_rad').median(), {'min':0,'max':10},\"VIIRS 2024\")\n",
        "\n",
        "Map = geemap.Map(center=[38.402, 127.096], zoom=7)\n",
        "Map.split_map(left_layer, right_layer)\n",
        "Map\n"
      ],
      "metadata": {
        "id": "9T8jfquszoXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# identify a 500 meter buffer around our Point Of Interest (POI)\n",
        "poi = ee.Geometry.Point(127.072483, 37.515817).buffer(500)\n",
        "\n",
        "viirs = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate('2014-01-01','2024-12-31')"
      ],
      "metadata": {
        "id": "INV3bCXtltcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** Extracting all image values in the collection\n",
        "\n",
        "To make a time series, we need to get all the values in our collection using the `map` function. We'll create a custom function in Python that takes a single image as an input and reduces the data in a given region (our point of interest in this case).\n",
        "\n",
        "We'll get the mean of the pixels in our region and set the scale to 30. We'll use the `avg_rad` band.\n",
        "\n",
        "We'll then need to set this reduced info as a property (we'll call it \"mean\") in our image so that the output of our function is to get the mean radiance of a particular region, and add this as a property on our image along with the date."
      ],
      "metadata": {
        "id": "CNTJmRxDk1yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def poi_mean(img):\n",
        "    mean = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=30).get('avg_rad')\n",
        "    return img.set('date', img.date().format()).set('mean',mean)"
      ],
      "metadata": {
        "id": "h5968lkWk1RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** We map this function to every image in our collection to get a new ImageCollection, but now each image has the mean value for the region of interest and the date. These are the data we'll make our time series out of."
      ],
      "metadata": {
        "id": "d2NDf-YqlGae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poi_reduced_imgs = viirs.map(poi_mean)"
      ],
      "metadata": {
        "id": "v7RmARWPlFba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** To convert to a pandas dataframe, we dont want an ImageCollection; however, so we will reduce our images to a list of lists:\n",
        "- for each image, we have a 2-element list that contains that images date and mean value (for our point of interest)\n",
        "- each of these lists are themselves elements in our outer list, which is what we'll convert to a dataframe"
      ],
      "metadata": {
        "id": "Wom8mFZvlY6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date','mean']).values().get(0)\n",
        "nested_list"
      ],
      "metadata": {
        "id": "ydrUppSBlWbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** This nested list can be turned into a dataframe using the `.DataFrame` constructor. We'll name the columns, \"date\" and \"mean\"."
      ],
      "metadata": {
        "id": "3gMMqY_TlfIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to call the callback method \"getInfo\" to retrieve the data\n",
        "df = pd.DataFrame(nested_list.getInfo(), columns=['date','mean'])\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "x7rjGn_zlkW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.** Now we have a dataframe with each observation (month) as a row and it has the timestamp and mean values.\n",
        "\n",
        "A reason pandas is so powerful is that it has built-ins, like a method to convert our string timestamp into a native timestamp data type.\n",
        "\n",
        "We will also set our date column to be our index. Doing these things allows our .plot library to automatically convert the dates into nice readable dates on our axis."
      ],
      "metadata": {
        "id": "cFCFObZmmCQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "df = df.set_index('date')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "w2o-j-Ibmtam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Create a time series graph for VIIRS-DNB from Jan 2014 to May 2020 for Seoul Olympic Stadium"
      ],
      "metadata": {
        "id": "8xwdGYs7mxN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "koreaMap = geemap.Map()\n",
        "koreaMap.centerObject(poi, zoom=15)\n",
        "koreaMap.add_basemap(\"SATELLITE\")\n",
        "koreaMap.addLayer(poi, {}, \"Seoul Olympic Stadium\")\n",
        "koreaMap.addLayerControl()\n",
        "koreaMap"
      ],
      "metadata": {
        "id": "PJSm4s-Cm7Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.** The buffer encompasses almost the entire Olympic complex.\n",
        "\n",
        "Pandas dataframes integrates nicely with our plotting libraries. We'll use seaborn to make a simple time series line plot."
      ],
      "metadata": {
        "id": "4SPIMZDQwAZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with pyplot and set the dimensions to 15 x 7\n",
        "fig, ax = plt.subplots(figsize=(15,7))\n",
        "\n",
        "# Create the plot by setting the dataframe to the data argument\n",
        "sns.lineplot(data=df, ax=ax)\n",
        "\n",
        "# Set the labels and title\n",
        "ax.set_ylabel('mean radiance',fontsize=20)\n",
        "ax.set_xlabel('date',fontsize=20)\n",
        "ax.set_title('Monthly mean radiance for Seoul Olympic Stadium (Jan 2014 to Jan 2024)',fontsize=20);"
      ],
      "metadata": {
        "id": "rmQ74jZwwZgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.** Brief observations: There are some strong seasonal patterns here (peaks and valleys), which is perhaps not too surprising for a sports stadium. There is also see a spike in late 2018 and 2022 as well as the drop-off in early 2020 that is very likely an indication of COVID-19 impacts.\n",
        "\n",
        "What is that spike? With dataframes it is easy to find the date of that peak using the `.idxmax()` method to get the index (which is the month) of the maximum value."
      ],
      "metadata": {
        "id": "SJJ7Zr7AwsHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.idxmax()"
      ],
      "metadata": {
        "id": "8qvggxvBxMa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "September is a popular month for many concerts and sporting events, and September 2018 was the venue's 30th anniversary."
      ],
      "metadata": {
        "id": "yT_JPD_Y5Wml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3 - Pulling Data Client-side with computePixels (or getPixels) and Data converters\n"
      ],
      "metadata": {
        "id": "-oGo7UXa5qPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1.** **Data converters** are client-side conversion capabilities built into getPixels, computePixels, listFeatures, and computeFeatures. By specifying a compatible fileFormat, these methods can return data in Python-native formats like structured NumPy arrays for rasters and Pandas DataFrames or GeoPandas GeoDataFrames for vectors. In the case of vectors, the listFeatures and computeFeatures methods will make several network requests to fetch all the pages of the table before returning the Python object.\n",
        "\n",
        "All of these methods transfer data from Earth Engine servers to a client machine using the interactive processing environment, which is optimized for answering small requests quickly. As such, it enforces limits on request size and compute time. You'll need to keep this in mind as you're coding your analysis and decide whether exporting data using the batch processing environment would be better. For example, see ee.date.computePixel limits in the reference docs.\n",
        "\n",
        "Some common use cases for data converters are fetching many small image tiles in parallel (e.g., training ML models or automated serial workflows) and for visualization and data exploration with your favorite Python libraries. This notebook focuses on data exploration and visualization; if you're interested in learning about fetching data in parallel, see the Medium blog post \"Pixels to the people!\"."
      ],
      "metadata": {
        "id": "CvypbgnhHLqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**2.** Computed Earth Engine data\n",
        "\n",
        "Computed Earth Engine data are those that are generated on the fly through instantiation of non-asset data, computation, or manipulation; they are not stored on disk for later retrieval. To request conversion of computed data, you can use the `ee.data.computeFeatures` and `ee.data.computePixels` functions for `ee.FeatureCollection` and `ee.Image` objects, respectively.\n",
        "\n",
        "To pull data from previously computed or imported Earth Engine assets, you would use `ee.data.getPixels`"
      ],
      "metadata": {
        "id": "_TLvhDXy8_Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** This exercise will utilize computePixels and Data converters to pull precipitation data directly from Earth Engine into a client-side NumPy array.\n",
        "\n",
        "First create a 12 band image (one band per month) from the [WorldClim Climatology ImageCollection](https://developers.google.com/earth-engine/datasets/catalog/WORLDCLIM_V1_MONTHLY#bands) using aggregate_array which aggregates over a given property of the objects in a collection, calculating a list of all the values of the selected property."
      ],
      "metadata": {
        "id": "0PL1U2AtHdUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wa = ee.FeatureCollection(BOUNDARIES_ID).filter(\n",
        "    'ADM0_NAME == \"United States of America\" && '\n",
        "    'ADM1_NAME == \"Washington\"'\n",
        ")\n",
        "\n",
        "precip = ee.ImageCollection('WORLDCLIM/V1/MONTHLY').select('prec')\n",
        "\n",
        "months = precip.aggregate_array('month').getInfo()\n",
        "\n",
        "band_names = [f'prec_month_{str(m).zfill(2)}' for m in months]\n",
        "\n",
        "monthly_precip = ee.Image(precip.toBands().rename(band_names))\n",
        "\n",
        "monthly_precip\n",
        "\n"
      ],
      "metadata": {
        "id": "_kyDJsea-Ds1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** Now, levearging computePixels, make several simultaneous calls to Earth Engine to create a client-side NumPy array of the image which is clipped to Washington State at a scale of 1,500 meters (to limit the amount of data returned to the client).\n"
      ],
      "metadata": {
        "id": "5EvPdO6VI47V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_precip_washington = monthly_precip.clipToBoundsAndScale(\n",
        "    geometry=wa, scale=1500\n",
        ")\n",
        "\n",
        "monthly_precip_npy = ee.data.computePixels({\n",
        "    'expression': monthly_precip_washington,\n",
        "    'fileFormat': 'NUMPY_NDARRAY'\n",
        "})\n",
        "\n",
        "monthly_precip_npy"
      ],
      "metadata": {
        "id": "A6vUhEe79y5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.** NumPy structured arrays work well for multiband image data. You can think of them as a table of arrays where each band is a column accessible from a field (band) name. It also permits each band to have a different data type.\n",
        "\n",
        "For example, get the list of field (band) names and then subset an array by name and print its shape and display a preview of it."
      ],
      "metadata": {
        "id": "Sp3yUwKzKBwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = monthly_precip_npy.dtype.names\n",
        "print('field names:', names)\n",
        "\n",
        "prec_month_10_arr = monthly_precip_npy['prec_month_10']\n",
        "print('Selected array (band) shape:', prec_month_10_arr.shape)\n",
        "display(prec_month_10_arr)\n",
        "plt.imshow(prec_month_10_arr, vmin=0, vmax=320)"
      ],
      "metadata": {
        "id": "dllMgxn6-jSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.** Since the array has *all* months of mean precipitation, we can use the matplotlib [`ImageGrid`](https://matplotlib.org/stable/gallery/axes_grid1/simple_axesgrid.html) function to show a time series grid for simple visual interpolation of intra-annual precipitation patterns."
      ],
      "metadata": {
        "id": "RzzShgr0KJuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure and grid.\n",
        "fig = plt.figure(figsize=(20.0, 20.0))\n",
        "grid = ImageGrid(\n",
        "    fig,\n",
        "    111,\n",
        "    nrows_ncols=(4, 3),\n",
        "    axes_pad=0.4,\n",
        "    cbar_mode=\"single\",\n",
        "    cbar_location=\"right\",\n",
        "    cbar_pad=0.4,\n",
        "    cbar_size=\"2%\",\n",
        ")\n",
        "\n",
        "# Display each band to a grid cell.\n",
        "for ax, name in zip(grid, names):\n",
        "    ax.imshow(monthly_precip_npy[name], vmin=0, vmax=500)\n",
        "    ax.set_title(name)\n",
        "\n",
        "# Add colorbar.\n",
        "colorbar = plt.colorbar(ax.get_children()[0], cax=grid[0].cax)\n",
        "colorbar.set_label(\"Precipitation (mm)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GcclIh-iGb_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4 - Server-side Processing for Zonal Statistics"
      ],
      "metadata": {
        "id": "MkTKMH9IKdBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** By now we've done a combination of both client-side downloading and server-side processing of raster data. Downloading raster data to the client can be useful for small jobs and sometimes is the right approach. However, often it is beneficial to leverage the power of Earth Engine to compute Zonal Statistics (reduceRegion, reduceRegions) server-side, and pull only the resulting statistics to the client.\n",
        "\n",
        "This example will demonstrate the creation of a continental-scale regular grid geometry in the client, then recreating that grid as a server-side geometry to use as the regions to calculate the zonal statisctis for mean air temperature for each cell in the grid over an 8 year period.\n",
        "\n",
        "Start by pulling the boundary of the United States from a BigQuery Public Dataset."
      ],
      "metadata": {
        "id": "bTPeeH1MLMYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"SELECT * FROM `bigquery-public-data.geo_us_boundaries.national_outline`\"\"\"\n",
        "conus = pd.read_gbq(query,project_id=project_id)\n",
        "\n",
        "conus = conus.iloc[:, 0].apply(loads) #get the geometric object from string\n",
        "conus = gpd.GeoDataFrame(conus, geometry=conus.name, crs='epsg:4326') #convert conus to a geodataframe\n",
        "conus"
      ],
      "metadata": {
        "id": "aDDBm52OMsZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Create a GeoDataFrame of a regular hexagonal H3 Grid for conus"
      ],
      "metadata": {
        "id": "zRpAn7MvOYsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hexgrid_us = h3fy(conus.buffer(0.01), resolution=4).reset_index()"
      ],
      "metadata": {
        "id": "eRxINNM-PGWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** Trim to just conus, select rows with latitudes (20 to 60) and longitudes (-130 to -65) and plot the GeoDataFrame."
      ],
      "metadata": {
        "id": "tNL6gnPeRnDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hexgrid_us['longitude'] = hexgrid_us['geometry'].apply(lambda x: x.centroid.coords.xy[0][0])\n",
        "hexgrid_us['latitude'] = hexgrid_us['geometry'].apply(lambda x: x.centroid.coords.xy[1][0])\n",
        "hexgrid_us = hexgrid_us[(hexgrid_us['longitude'].between(-130, -65)) & (hexgrid_us['latitude'].between(20, 60))][['hex_id', 'geometry']]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(30, 26))\n",
        "\n",
        "hexgrid_us.plot(ax=ax, color='orange', edgecolor='grey', alpha=0.6)\n",
        "ax.set_axis_off()"
      ],
      "metadata": {
        "id": "YBTkYs_rRvgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** The 'hexgrid_us' GeoDataFrame is more than 4,200 individual polygons. We COULD pull back a lot of data to the client and intersect and calculate a statistic on the intersection of each of these polygons in the client, but instead, we will push them to Earth Engine as a FeatureCollection and use reduceRegions to return just a table of the statistic we want."
      ],
      "metadata": {
        "id": "eH0uQ1HRSL0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Earth Engine Feature from a Shapely geometry\n",
        "def get_ee_feature(geom):\n",
        "    x,y = geom.exterior.coords.xy\n",
        "    coords = np.dstack((x,y)).tolist()\n",
        "    g = ee.Geometry.Polygon(coords)\n",
        "    return ee.Feature(g)\n",
        "\n",
        "features = ee.FeatureCollection([get_ee_feature(x[1].geometry) for x in hexgrid_us.iterrows()])\n",
        "\n",
        "# Create a single image from an ImageCollection and select the band you are interested in\n",
        "image_collection = ee.ImageCollection(\"ECMWF/ERA5_LAND/MONTHLY_AGGR\")\n",
        "image = image_collection.filterDate('2015-01-01', '2023-12-31').select('temperature_2m').mean()\n",
        "\n",
        "# Calculate Zonal Statistics on Eart Engine and create a GeoDataFrame\n",
        "zone_stats = image.reduceRegions(collection=features, reducer=ee.Reducer.mean(), scale=11132, tileScale=1).getInfo()\n",
        "zone_stats = gpd.GeoDataFrame.from_features(zone_stats, crs='epsg:4326')"
      ],
      "metadata": {
        "id": "4HUVsTPtSsUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.** Plot a chloropleth map of the GeoDataFrame based on the statistics for each zone that was calculated in Earth Engine"
      ],
      "metadata": {
        "id": "tBtg8wmMTLUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax= plt.subplots(figsize=(30,26))\n",
        "\n",
        "# Define the legend axes\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
        "\n",
        "# Plot the US map with hexagons where the colour of each hexagon represents the mean air temperature value\n",
        "zone_stats.plot(column='mean', ax=ax, cmap='OrRd', legend=True, cax=cax)\n",
        "\n",
        "# Customise the legend\n",
        "cax.minorticks_on()\n",
        "cax.tick_params(which='major', direction='in', length=18, width=2, labelsize=24)\n",
        "cax.tick_params(which='minor', direction='in', length=12, width=2, labelsize=24)\n",
        "cax.set_title('Temperature (K)', fontsize=24)\n",
        "\n",
        "# Turn the x-axis and y-axis off\n",
        "ax.set_axis_off()"
      ],
      "metadata": {
        "id": "eI_ZV9oqTgaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}